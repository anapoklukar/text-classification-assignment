{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d317450-1724-4c19-a252-c64ee1291649",
   "metadata": {},
   "source": [
    "# Assignment 2: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72af0130-4c6f-47f8-8c35-dd9daa6d007f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4fe8d0-0339-4622-9a46-59f3999afaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# Initialize an empty list to store processed entries\n",
    "processed_data = []\n",
    "\n",
    "# Read the JSON file and process each line\n",
    "with open('News_Category_Dataset_IS_course.json', 'r') as file:\n",
    "    for line in file:\n",
    "        # Parse the JSON data for each line\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        # Extract relevant information\n",
    "        link = entry[\"link\"]\n",
    "        headline = entry[\"headline\"]\n",
    "        category = entry[\"category\"]\n",
    "        short_description = entry[\"short_description\"]\n",
    "        authors = entry[\"authors\"]\n",
    "        \n",
    "        # Convert the date from milliseconds to a human-readable format\n",
    "        date = entry[\"date\"]\n",
    "        formatted_date = datetime.datetime.utcfromtimestamp(date / 1000.0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Store the processed entry in the list\n",
    "        processed_entry = {\n",
    "            \"link\": link,\n",
    "            \"headline\": headline,\n",
    "            \"category\": category,\n",
    "            \"short_description\": short_description,\n",
    "            \"authors\": authors,\n",
    "            \"date\": formatted_date\n",
    "        }\n",
    "        processed_data.append(processed_entry)\n",
    "\n",
    "# Write processed data to a CSV file\n",
    "csv_file_path = 'processed_data.csv'\n",
    "fieldnames = [\"link\", \"headline\", \"category\", \"short_description\", \"authors\", \"date\"]\n",
    "\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write data\n",
    "    for entry in processed_data:\n",
    "        writer.writerow(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b77b21-762b-4c92-8f31-ae1cf38e3a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/dodgers-basebal...</td>\n",
       "      <td>Maury Wills, Base-Stealing Shortstop For Dodge...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Maury Wills, who helped the Los Angeles Dodger...</td>\n",
       "      <td>Beth Harris, AP</td>\n",
       "      <td>2022-09-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/golden-globes-r...</td>\n",
       "      <td>Golden Globes Returning To NBC In January Afte...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>For the past 18 months, Hollywood has effectiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/biden-us-forces...</td>\n",
       "      <td>Biden Says U.S. Forces Would Defend Taiwan If ...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>President issues vow as tensions with China rise.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148117</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/girl-with...</td>\n",
       "      <td>'Girl With the Dragon Tattoo' India Release Ca...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>\"Sony Pictures will not be releasing The Girl ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148118</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/maria-sha...</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148119</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/super-bow...</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148120</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/aldon-smi...</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148121</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/dwight-ho...</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148122 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     link  \\\n",
       "0       https://www.huffpost.com/entry/funniest-tweets...   \n",
       "1       https://www.huffpost.com/entry/funniest-parent...   \n",
       "2       https://www.huffpost.com/entry/dodgers-basebal...   \n",
       "3       https://www.huffpost.com/entry/golden-globes-r...   \n",
       "4       https://www.huffpost.com/entry/biden-us-forces...   \n",
       "...                                                   ...   \n",
       "148117  https://www.huffingtonpost.com/entry/girl-with...   \n",
       "148118  https://www.huffingtonpost.com/entry/maria-sha...   \n",
       "148119  https://www.huffingtonpost.com/entry/super-bow...   \n",
       "148120  https://www.huffingtonpost.com/entry/aldon-smi...   \n",
       "148121  https://www.huffingtonpost.com/entry/dwight-ho...   \n",
       "\n",
       "                                                 headline       category  \\\n",
       "0       23 Of The Funniest Tweets About Cats And Dogs ...         COMEDY   \n",
       "1       The Funniest Tweets From Parents This Week (Se...      PARENTING   \n",
       "2       Maury Wills, Base-Stealing Shortstop For Dodge...         SPORTS   \n",
       "3       Golden Globes Returning To NBC In January Afte...  ENTERTAINMENT   \n",
       "4       Biden Says U.S. Forces Would Defend Taiwan If ...       POLITICS   \n",
       "...                                                   ...            ...   \n",
       "148117  'Girl With the Dragon Tattoo' India Release Ca...  ENTERTAINMENT   \n",
       "148118  Maria Sharapova Stunned By Victoria Azarenka I...         SPORTS   \n",
       "148119  Giants Over Patriots, Jets Over Colts Among  M...         SPORTS   \n",
       "148120  Aldon Smith Arrested: 49ers Linebacker Busted ...         SPORTS   \n",
       "148121  Dwight Howard Rips Teammates After Magic Loss ...         SPORTS   \n",
       "\n",
       "                                        short_description           authors  \\\n",
       "0       \"Until you have a dog you don't understand wha...     Elyse Wanshel   \n",
       "1       \"Accidentally put grown-up toothpaste on my to...  Caroline Bologna   \n",
       "2       Maury Wills, who helped the Los Angeles Dodger...   Beth Harris, AP   \n",
       "3       For the past 18 months, Hollywood has effectiv...               NaN   \n",
       "4       President issues vow as tensions with China rise.               NaN   \n",
       "...                                                   ...               ...   \n",
       "148117  \"Sony Pictures will not be releasing The Girl ...               NaN   \n",
       "148118  Afterward, Azarenka, more effusive with the pr...               NaN   \n",
       "148119  Leading up to Super Bowl XLVI, the most talked...               NaN   \n",
       "148120  CORRECTION: An earlier version of this story i...               NaN   \n",
       "148121  The five-time all-star center tore into his te...               NaN   \n",
       "\n",
       "                       date  \n",
       "0       2022-09-23 00:00:00  \n",
       "1       2022-09-23 00:00:00  \n",
       "2       2022-09-20 00:00:00  \n",
       "3       2022-09-20 00:00:00  \n",
       "4       2022-09-19 00:00:00  \n",
       "...                     ...  \n",
       "148117  2012-01-28 00:00:00  \n",
       "148118  2012-01-28 00:00:00  \n",
       "148119  2012-01-28 00:00:00  \n",
       "148120  2012-01-28 00:00:00  \n",
       "148121  2012-01-28 00:00:00  \n",
       "\n",
       "[148122 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('processed_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ad0e2b-6138-4d8f-a8ab-adb65a14c0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>148122</td>\n",
       "      <td>147388</td>\n",
       "      <td>148122</td>\n",
       "      <td>135938</td>\n",
       "      <td>123706</td>\n",
       "      <td>148122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>148096</td>\n",
       "      <td>146295</td>\n",
       "      <td>15</td>\n",
       "      <td>133792</td>\n",
       "      <td>19633</td>\n",
       "      <td>3618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.huffingtonpost.comhttp://www.newre...</td>\n",
       "      <td>Sunday Roundup</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Welcome to the HuffPost Rise Morning Newsbrief...</td>\n",
       "      <td>Lee Moran</td>\n",
       "      <td>2014-11-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>35602</td>\n",
       "      <td>191</td>\n",
       "      <td>2058</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     link        headline  \\\n",
       "count                                              148122          147388   \n",
       "unique                                             148096          146295   \n",
       "top     https://www.huffingtonpost.comhttp://www.newre...  Sunday Roundup   \n",
       "freq                                                    2              90   \n",
       "\n",
       "        category                                  short_description  \\\n",
       "count     148122                                             135938   \n",
       "unique        15                                             133792   \n",
       "top     POLITICS  Welcome to the HuffPost Rise Morning Newsbrief...   \n",
       "freq       35602                                                191   \n",
       "\n",
       "          authors                 date  \n",
       "count      123706               148122  \n",
       "unique      19633                 3618  \n",
       "top     Lee Moran  2014-11-05 00:00:00  \n",
       "freq         2058                   98  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8da2575-182b-4e4f-b088-3a380863a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data Summary:\n",
      "link                     0\n",
      "headline               734\n",
      "category                 0\n",
      "short_description    12184\n",
      "authors              24416\n",
      "date                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data in each column\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# Print the count of missing values for each column\n",
    "print(\"Missing Data Summary:\")\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf11eb8-8e5e-47a7-b060-4da9df3a6f16",
   "metadata": {},
   "source": [
    "We are not removing the data that has missing short_description and author, since they are a big fraction of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9105b4-4441-4298-8987-b04376813297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                 object\n",
       "headline             object\n",
       "category             object\n",
       "short_description    object\n",
       "authors              object\n",
       "date                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dta types of columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61674786-a50a-4dfb-a7d4-4f801b3e35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything but date to string\n",
    "df['link'] = df['link'].astype(\"string\")\n",
    "df['headline'] = df['headline'].astype(\"string\")\n",
    "df['category'] = df['category'].astype(\"string\")\n",
    "df['short_description'] = df['short_description'].astype(\"string\")\n",
    "df['authors'] = df['authors'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f4e4d-4a0d-4743-bf82-4ffd26e2a2e3",
   "metadata": {},
   "source": [
    "## Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c2c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2b561a-d9e5-4c07-a067-d0132d0d3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download necessary resources (if not already downloaded)\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lemmatizer and Stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d9d5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Stemming (uncomment if you want to use stemming)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Join the words back into a string\n",
    "    preprocessed_text = ' '.join(lemmatized_words)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efdb7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess links (remove everything up to /entry/ and remove the '-' characters)\n",
    "def preprocess_link(link):\n",
    "    # Remove everything up to /entry/ if it exists\n",
    "    if '/entry/' in link:\n",
    "        link = link.split('/entry/')[1]\n",
    "    \n",
    "    #Remove everything after the first '_' character if it exists\n",
    "    if '_' in link:\n",
    "        link = link.split('_')[0]\n",
    "\n",
    "    # Remove the '-' characters if they exist\n",
    "    if '-' in link:\n",
    "        link = link.replace('-', ' ')\n",
    "\n",
    "    #preprocess the link text\n",
    "    link = preprocess_text(link)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb5696ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the preprocessing function to the headline column only in rows where the headline isn't missing\n",
    "df.loc[df['headline'].notnull(), 'headline'] = df.loc[df['headline'].notnull(), 'headline'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be6113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the preprocessing to short_description and links as well\n",
    "df.loc[df['short_description'].notnull(), 'short_description'] = df.loc[df['short_description'].notnull(), 'short_description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2738a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the authors where the authors aren't missing\n",
    "df.loc[df['authors'].notnull(), 'authors'] = df.loc[df['authors'].notnull(), 'authors'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "285ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the links where the links aren't missing\n",
    "df.loc[df['link'].notnull(), 'link'] = df.loc[df['link'].notnull(), 'link'].apply(preprocess_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5669dead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "                                                link  \\\n",
      "0  https://www.huffpost.com/entry/funniest-tweets...   \n",
      "1  https://www.huffpost.com/entry/funniest-parent...   \n",
      "2  https://www.huffpost.com/entry/dodgers-basebal...   \n",
      "3  https://www.huffpost.com/entry/golden-globes-r...   \n",
      "4  https://www.huffpost.com/entry/biden-us-forces...   \n",
      "\n",
      "                                            headline       category  \\\n",
      "0  23 Of The Funniest Tweets About Cats And Dogs ...         COMEDY   \n",
      "1  The Funniest Tweets From Parents This Week (Se...      PARENTING   \n",
      "2  Maury Wills, Base-Stealing Shortstop For Dodge...         SPORTS   \n",
      "3  Golden Globes Returning To NBC In January Afte...  ENTERTAINMENT   \n",
      "4  Biden Says U.S. Forces Would Defend Taiwan If ...       POLITICS   \n",
      "\n",
      "                                   short_description           authors  \\\n",
      "0  \"Until you have a dog you don't understand wha...     Elyse Wanshel   \n",
      "1  \"Accidentally put grown-up toothpaste on my to...  Caroline Bologna   \n",
      "2  Maury Wills, who helped the Los Angeles Dodger...   Beth Harris, AP   \n",
      "3  For the past 18 months, Hollywood has effectiv...               NaN   \n",
      "4  President issues vow as tensions with China rise.               NaN   \n",
      "\n",
      "                  date  \n",
      "0  2022-09-23 00:00:00  \n",
      "1  2022-09-23 00:00:00  \n",
      "2  2022-09-20 00:00:00  \n",
      "3  2022-09-20 00:00:00  \n",
      "4  2022-09-19 00:00:00  \n",
      "\n",
      "Preprocessed Data:\n",
      "                                link  \\\n",
      "0   funniest tweet cat dog september   \n",
      "1           funniest parenting tweet   \n",
      "2          dodger baseball obit will   \n",
      "3            golden globe return nbc   \n",
      "4  biden u force defend taiwan china   \n",
      "\n",
      "                                            headline       category  \\\n",
      "0                        funniest tweet cat dog week         COMEDY   \n",
      "1                         funniest tweet parent week      PARENTING   \n",
      "2                     maury will shortstop dodger dy         SPORTS   \n",
      "3            golden globe returning nbc january year  ENTERTAINMENT   \n",
      "4  biden say force would defend taiwan china invaded       POLITICS   \n",
      "\n",
      "                                   short_description           authors  \\\n",
      "0                         dog understand could eaten     elyse wanshel   \n",
      "1  accidentally put toothpaste toddler toothbrush...  caroline bologna   \n",
      "2  maury helped los angeles dodger win three worl...    beth harris ap   \n",
      "3  past month hollywood effectively boycotted glo...              <NA>   \n",
      "4             president issue vow tension china rise              <NA>   \n",
      "\n",
      "                  date  \n",
      "0  2022-09-23 00:00:00  \n",
      "1  2022-09-23 00:00:00  \n",
      "2  2022-09-20 00:00:00  \n",
      "3  2022-09-20 00:00:00  \n",
      "4  2022-09-19 00:00:00  \n"
     ]
    }
   ],
   "source": [
    "original = pd.read_csv('processed_data.csv')\n",
    "#compare the first 5 rows of the original and preprocessed data, each column side by side\n",
    "pd.concat([original, df], axis=1).head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
